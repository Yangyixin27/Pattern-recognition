{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "## EE559 HW Wk2, Prof. Jenkins, Spring 2018\n",
    "## Created by Arindam Jati, TA\n",
    "## Tested in Python 3.6.3, OSX El Captain\n",
    "################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def plotDecBoundaries(training, label_train, sample_mean):\n",
    "\n",
    "    #Plot the decision boundaries and data points for minimum distance to\n",
    "    #class mean classifier\n",
    "    #\n",
    "    # training: traning data\n",
    "    # label_train: class lables correspond to training data\n",
    "    # sample_mean: mean vector for each class\n",
    "    #\n",
    "    # Total number of classes\n",
    "    nclass =  max(np.unique(label_train))\n",
    "\n",
    "    # Set the feature range for ploting\n",
    "    max_x = np.ceil(max(training[:, 0])) + 1\n",
    "    min_x = np.floor(min(training[:, 0])) - 1\n",
    "    max_y = np.ceil(max(training[:, 1])) + 1\n",
    "    min_y = np.floor(min(training[:, 1])) - 1\n",
    "\n",
    "    xrange = (min_x, max_x)\n",
    "    yrange = (min_y, max_y)\n",
    "\n",
    "    # step size for how finely you want to visualize the decision boundary.\n",
    "    inc = 0.005\n",
    "\n",
    "    # generate grid coordinates. this will be the basis of the decision\n",
    "    # boundary visualization.\n",
    "    (x, y) = np.meshgrid(np.arange(xrange[0], xrange[1]+inc/100, inc), np.arange(yrange[0], yrange[1]+inc/100, inc))\n",
    "\n",
    "    # size of the (x, y) image, which will also be the size of the\n",
    "    # decision boundary image that is used as the plot background.\n",
    "    image_size = x.shape\n",
    "    xy = np.hstack( (x.reshape(x.shape[0]*x.shape[1], 1, order='F'), y.reshape(y.shape[0]*y.shape[1], 1, order='F')) ) # make (x,y) pairs as a bunch of row vectors.\n",
    "\n",
    "    # distance measure evaluations for each (x,y) pair.\n",
    "    dist_mat = cdist(xy, sample_mean)\n",
    "    pred_label = np.argmin(dist_mat, axis=1)\n",
    "\n",
    "    # reshape the idx (which contains the class label) into an image.\n",
    "    decisionmap = pred_label.reshape(image_size, order='F')\n",
    "\n",
    "    #show the image, give each coordinate a color according to its class label\n",
    "    plt.imshow(decisionmap, extent=[xrange[0], xrange[1], yrange[0], yrange[1]], origin='lower')\n",
    "\n",
    "    # plot the class training data.\n",
    "    plt.plot(training[label_train == 1, 0],training[label_train == 1, 1], 'rx')\n",
    "    plt.plot(training[label_train == 2, 0],training[label_train == 2, 1], 'go')\n",
    "    if nclass == 3:\n",
    "        plt.plot(training[label_train == 3, 0],training[label_train == 3, 1], 'b*')\n",
    "\n",
    "    # include legend for training data\n",
    "    if nclass == 3:\n",
    "        l = plt.legend(('Class 1', 'Class 2', 'Class 3'), loc=2)\n",
    "    else:\n",
    "        l = plt.legend(('Class 1', 'Class 2'), loc=2)\n",
    "    plt.gca().add_artist(l)\n",
    "\n",
    "    # plot the class mean vector.\n",
    "    m1, = plt.plot(sample_mean[0,0], sample_mean[0,1], 'rd', markersize=12, markerfacecolor='r', markeredgecolor='w')\n",
    "    m2, = plt.plot(sample_mean[1,0], sample_mean[1,1], 'gd', markersize=12, markerfacecolor='g', markeredgecolor='w')\n",
    "    if nclass == 3:\n",
    "        m3, = plt.plot(sample_mean[2,0], sample_mean[2,1], 'bd', markersize=12, markerfacecolor='b', markeredgecolor='w')\n",
    "\n",
    "    # include legend for class mean vector\n",
    "    if nclass == 3:\n",
    "        l1 = plt.legend([m1,m2,m3],['Class 1 Mean', 'Class 2 Mean', 'Class 3 Mean'], loc=4)\n",
    "    else:\n",
    "        l1 = plt.legend([m1,m2], ['Class 1 Mean', 'Class 2 Mean'], loc=4)\n",
    "\n",
    "    plt.gca().add_artist(l1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Calculate the sample_mean for given XY coordinate and label\n",
    "def Sample_Mean(xy_data,label):\n",
    "    nclass =int(max(np.unique(label))) #number of classes\n",
    "    sample=np.array([[float(0)]*len(xy_data[0]) for _ in range(nclass)])\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        index=int(label[i])-1\n",
    "        sample[index]= sample[index]+xy_data[i] #sum of the same class\n",
    "    for i in range(nclass):\n",
    "        sample[i] =sample[i]/list(label).count(i+1) #calculate average\n",
    "    sample_mean=np.array(sample)\n",
    "    return sample_mean\n",
    "\n",
    "\n",
    "# Train the first synthetic1_train\n",
    "csvFile = np.loadtxt(\"synthetic1_train.csv\", dtype=np.float, delimiter=\",\")\n",
    "sample_mean_1 = Sample_Mean(csvFile[:,:-1],csvFile[:,-1])\n",
    "\n",
    "for i in range(len(sample_mean_1)):\n",
    "    print (\"class %d mean is : %s\"%(i,str(sample_mean_1[i])))\n",
    "plotDecBoundaries(csvFile[:,:2],csvFile[:,-1],sample_mean_1)\n",
    "\n",
    "\n",
    "#Calculate the error rate for given XY coordinate, label and sample_mean \n",
    "def Error_Rate(xy_data,label,sample_mean):\n",
    "    golden_label = label\n",
    "    dist_mat = cdist(xy_data, sample_mean)\n",
    "    pred_label = np.argmin(dist_mat, axis=1)+1\n",
    "    error_num=0\n",
    "    for i in range(len(pred_label)):   # count the number of errors\n",
    "        if pred_label[i] != golden_label[i]:\n",
    "            error_num+=1                \n",
    "    return error_num/float(len(golden_label))   \n",
    "\n",
    "#Output the error rate for training and testing data\n",
    "error_rate_1=Error_Rate(csvFile[:,:-1],csvFile[:,-1],sample_mean_1)\n",
    "print (\"error rate for synthetic1_train data is %s%%\"%(error_rate_1*100))\n",
    "\n",
    "testFile = np.loadtxt(\"synthetic1_test.csv\", dtype=np.float, delimiter=\",\")\n",
    "error_rate_test_1=Error_Rate(testFile[:,:-1],testFile[:,-1],sample_mean_1)\n",
    "print (\"error rate for synthetic1_test data is %s%%\"%(error_rate_test_1*100))\n",
    "print (\"\\n\")\n",
    "\n",
    "# Train the synthetic2 data\n",
    "training_data_2=np.loadtxt(\"synthetic2_train.csv\", dtype=np.float, delimiter=\",\")\n",
    "sample_mean_2 = Sample_Mean(training_data_2[:,:-1],training_data_2[:,-1])\n",
    "\n",
    "for i in range(len(sample_mean_2)):\n",
    "    print (\"class %d mean is : %s\"%(i,str(sample_mean_2[i])))\n",
    "plotDecBoundaries(training_data_2[:,:-1],training_data_2[:,-1],sample_mean_2)\n",
    "\n",
    "#Output the error rate for training and testing data\n",
    "error_rate = Error_Rate(training_data_2[:,:-1],training_data_2[:,-1],sample_mean_2)\n",
    "print (\"error rate for synthetic2_train data is %s%%\"%(error_rate*100))\n",
    "\n",
    "test_data_2=np.loadtxt(\"synthetic2_test.csv\", dtype=np.float, delimiter=\",\")\n",
    "error_rate = Error_Rate(test_data_2[:,:-1],test_data_2[:,-1],sample_mean_2)\n",
    "print (\"error rate for synthetic2_test data is %s%%\"%(error_rate*100))\n",
    "print (\"\\n\")\n",
    "\n",
    "# Train the wine data, just use the first two columns as XY data\n",
    "wine_data=np.loadtxt(\"wine_train.csv\", dtype=np.float, delimiter=\",\")\n",
    "wine_xy=wine_data[:,:2]\n",
    "wine_label=wine_data[:,-1]\n",
    "sample_mean_wine = Sample_Mean(wine_xy,wine_label)\n",
    "\n",
    "for i in range(len(sample_mean_wine)):\n",
    "    print (\"class %d mean is : %s\"%(i,str(sample_mean_wine[i])))\n",
    "plotDecBoundaries(wine_xy,wine_label,sample_mean_wine)\n",
    "\n",
    "#Output the error rate for training and testing data\n",
    "error_rate = Error_Rate(wine_xy,wine_label,sample_mean_wine)\n",
    "print (\"error rate for wine train data is %s%%\"%(error_rate*100))\n",
    "\n",
    "wine_test_data=np.loadtxt(\"wine_test.csv\", dtype=np.float, delimiter=\",\")\n",
    "wine_test_xy=wine_test_data[:,:2]\n",
    "wine_test_label=wine_test_data[:,-1]\n",
    "error_rate = Error_Rate(wine_test_xy,wine_test_label,sample_mean_wine)\n",
    "print (\"error rate for wine test data is %s%%\"%(error_rate*100))\n",
    "print (\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Go through all the possible pairs and calculate the error rate for each pair.\n",
    "\n",
    "min_ij=[]\n",
    "min_error_rate=float(\"inf\")\n",
    "for i in range(len(wine_data[0])-2):\n",
    "    for j in range(i+1,len(wine_data[0])-1):\n",
    "        wine_x=wine_data[:,i]\n",
    "        wine_y=wine_data[:,j]\n",
    "        wine_new_xy=np.vstack((wine_x,wine_y))\n",
    "        wine_new_xy=wine_new_xy.T\n",
    "        sample_mean_wine = Sample_Mean(wine_new_xy,wine_label)\n",
    "        error_rate=Error_Rate(wine_new_xy,wine_label,sample_mean_wine)\n",
    "        \n",
    "        wine_test_x=wine_test_data[:,i]\n",
    "        wine_test_y=wine_test_data[:,j]\n",
    "        wine_test_new_xy=np.vstack((wine_test_x,wine_test_y))\n",
    "        wine_test_new_xy=wine_test_new_xy.T\n",
    "        sample_mean_wine = Sample_Mean(wine_test_new_xy,wine_test_label)\n",
    "        test_error_rate=Error_Rate(wine_test_new_xy,wine_test_label,sample_mean_wine)\n",
    "        \n",
    "        '''\n",
    "        # Use this to output every error_rate\n",
    "        print ([i,j])\n",
    "        print (\"%s%%\"%(error_rate*100))\n",
    "        print (\"%s%%\"%(test_error_rate*100))\n",
    "        '''\n",
    "        if error_rate < min_error_rate:\n",
    "            min_ij=[i,j]\n",
    "            min_error_rate= error_rate\n",
    "       \n",
    "print (\"The minimum error_rate for wine training data is: %s%%\"%(min_error_rate*100))\n",
    "print (\"Which means the error number is: %s\"%(min_error_rate*len(wine_data)))\n",
    "print (\"And the index is: %s\" %min_ij)\n",
    "wine_x=wine_data[:,min_ij[0]]\n",
    "wine_y=wine_data[:,min_ij[1]]\n",
    "wine_new_xy=np.vstack((wine_x,wine_y))\n",
    "wine_new_xy=wine_new_xy.T\n",
    "\n",
    "sample_mean_wine_new = Sample_Mean(wine_new_xy,wine_label)\n",
    "for i in range(len(sample_mean_wine)):\n",
    "    print (\"class %d mean is : %s\"%(i,str(sample_mean_wine_new[i])))\n",
    "plotDecBoundaries(wine_new_xy,wine_label,sample_mean_wine_new)\n",
    "\n",
    "#Calculate the error rate for [0,11] data\n",
    "wine_x=wine_test_data[:,min_ij[0]]\n",
    "wine_y=wine_test_data[:,min_ij[1]]\n",
    "wine_new_xy=np.vstack((wine_x,wine_y))\n",
    "wine_new_xy=wine_new_xy.T\n",
    "error_rate=Error_Rate(wine_new_xy,wine_test_label,sample_mean_wine_new)\n",
    "print (\"The minimum error rate for wine test data is %s%%\"%(error_rate*100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
